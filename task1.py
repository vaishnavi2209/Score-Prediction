# -*- coding: utf-8 -*-
"""TASK1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1m0K8UTQNdX7S-cYWKR7Bys2a0Oi39jNS

**Author - Vaishnavi Patel**

---


# Grip@ The Spark Foundation Task 1
# **Prediction using Supervised ML**

Importing all the required libraries
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
# %matplotlib inline
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn import metrics

"""# Load the dataset"""

# Reading data from remote link
url = "http://bit.ly/w-data"
df = pd.read_csv(url)
print("Successfully imported data into console" )  

df.head(20)

df.info()

"""# Visualizing the Dataset"""

# Plotting the distribution of scores
df.plot(x='Hours', y='Scores', style='o')  
plt.title('Hours vs Percentage')  
plt.xlabel('Hours Studied')  
plt.ylabel('Percentage Score')  
plt.show()

df.corr()  #checking correlation between hours and scores

"""From the above graph we can see that there is positive linear relation between Hours Studied & Percentage Score

### **Preparing the data**

The next step is to divide the data into "attributes" (inputs) and "labels" (outputs).
"""

X = df.iloc[:, :-1].values  
y = df.iloc[:, 1].values

"""Now that we have our attributes and labels, the next step is to split this data into training and test sets.
We'll do this by using Scikit-Learn's built-in train_test_split() method:
"""

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix,accuracy_score 

X_train, X_test, y_train, y_test = train_test_split(X, y, 
                            test_size=0.3, random_state=0) 
logmodel = LogisticRegression(solver='liblinear', random_state=0).fit(X, y)
logmodel.fit(X_train, y_train)

"""### **Training the Algorithm**
We have split our data into training and testing sets, and now is finally the time to train our algorithm. 
"""

from sklearn.linear_model import LinearRegression  
regression = LinearRegression()  
regression.fit(X_train, y_train) 

print("Training complete !")

# Plotting the regression line
line = regression.coef_*X+regression.intercept_

# Plotting for the test data
plt.title('Regression Line')
plt.scatter(X, y,c="darkblue")
plt.plot(X, line);
plt.show()

"""### **Making Predictions**
Now that we have trained our algorithm, it's time to make some predictions.
"""

print(X_test) # Testing data - In Hours
y_pred = regression.predict(X_test) # Predicting the scores
y_pred

# Comparing Actual vs Predicted
df = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})  
df

#Plotting bar chart to see the difference between actual vs predicted 
df.plot(kind='kde', figsize=(7, 7))
plt.show()

# You can also test with your own data
hours = [3.5]
own_pred = regression.predict([hours])  
print("Number of hours = {}".format(hours))  
print("Prediction Score = {}".format(round(own_pred[0],2)))

"""### **Evaluating the model**

The final step is to evaluate the performance of algorithm. This step is particularly important to compare how well different algorithms perform on a particular dataset. For simplicity here, we have chosen the mean square error. There are many such metrics.
"""

from sklearn import metrics  
print('Mean Absolute Error:', 
      metrics.mean_absolute_error(y_test, y_pred))